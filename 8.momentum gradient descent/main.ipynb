{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/workspace/my-deep-learning/8.momentum gradient descent/opt_utils.py:76: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(parameters['W' + str(l)].shape == layer_dims[l], layer_dims[l-1])\n",
      "/home/linux/workspace/my-deep-learning/8.momentum gradient descent/opt_utils.py:77: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(parameters['W' + str(l)].shape == layer_dims[l], 1)\n"
     ]
    }
   ],
   "source": [
    "# 引入必需的库\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import math\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "\n",
    "from opt_utils import load_params_and_grads, initialize_parameters, forward_propagation, backward_propagation\n",
    "from opt_utils import compute_cost, predict, predict_dec, plot_decision_boundary, load_dataset\n",
    "from testCases import *\n",
    "\n",
    "\n",
    "# 设置绘图参数\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (7.0, 4.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 动量梯度下降的效果\n",
    "\n",
    "![](./images/opt_momentum.png)\n",
    "\n",
    "下图中红色的箭头就是使用了动量梯度下降后的学习路径，蓝色的虚线是原始的路径。可以看出新路径比老路径要平滑。\n",
    "\n",
    "# 计算详解\n",
    "\n",
    "![](./images/introduce.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化指数加权平均值字典\n",
    "\n",
    "def initialize_velocity(parameters):\n",
    "    L = len(parameters) // 2 # 神经网络层数\n",
    "    v = {}\n",
    "\n",
    "    for l in range(L):\n",
    "        v['dW' + str(l + 1)] = np.zeros_like(parameters['W' + str(l + 1)])\n",
    "        v['db' + str(l + 1)] = np.zeros_like(parameters['b' + str(l + 1)])\n",
    "\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用动量梯度下降算法来更新参数\n",
    "\n",
    "def update_parameters_with_momentum(parameters, grads, v, beta, learning_rate):\n",
    "    L = len(parameters) // 2 # 神经网络层数\n",
    "\n",
    "    for l in range(L):\n",
    "        v['dW' + str(l + 1)] = beta * v['dW' + str(l + 1)] + (1 - beta) * grads['dW' + str(l + 1)]\n",
    "        v['db' + str(l + 1)] = beta * v['db' + str(l + 1)] + (1 - beta) * grads['db' + str(l + 1)]\n",
    "\n",
    "        # 更新参数\n",
    "        parameters['W' + str(l + 1)] = parameters['W' + str(l + 1)] - learning_rate * v['dW' + str(l + 1)]\n",
    "        parameters['b' + str(l + 1)] = parameters['b' + str(l + 1)] - learning_rate * v['db' + str(l + 1)]\n",
    "    \n",
    "    return parameters, v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 注意\n",
    "\n",
    "- 这里的指数加权平均值是没有添加修正算法的，所以前面一小段的梯度下降中，均势平均值是不准确的\n",
    "- 如果 beta = 0，则编程普通的标准梯度下降算法了\n",
    "\n",
    "# beta 选择\n",
    "\n",
    "- beta 越大，则学习路径越平滑，如果 beta 太大，则不能准确实时反映梯度的真实情况\n",
    "- beta 取值是 0.8 - 0.999，常用默认值为 0.9\n",
    "\n",
    "# 其他\n",
    "\n",
    "- 动量梯度下降可以用于 batch 梯度下降，也可以用于 mini-batch 梯度下降和随机梯度下降"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "133e0a373141b86a74d8ce31a3386c60afe8de1148488403c9ad7c02ff4c740c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('directml': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
